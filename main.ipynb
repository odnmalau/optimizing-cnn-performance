{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library yang diperlukan\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "# Atur seed untuk reproduksibilitas\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "def load_cifake_dataset(base_dir, sample_size=5000, val_split=0.15, random_state=42):\n",
    "    \"\"\"\n",
    "    Load dataset CIFAKE dari struktur folder yang sudah ada\n",
    "    \n",
    "    Args:\n",
    "        base_dir: direktori utama dataset ('dataset')\n",
    "        sample_size: jumlah total sampel yang diambil (dibagi sama antara real dan fake)\n",
    "        val_split: proporsi data validasi (diambil dari data training)\n",
    "        random_state: nilai random seed untuk reproduksibilitas\n",
    "    \n",
    "    Returns:\n",
    "        x_train, y_train, x_val, y_val, x_test, y_test\n",
    "    \"\"\"\n",
    "    # Set random seed\n",
    "    np.random.seed(random_state)\n",
    "    random.seed(random_state)\n",
    "    \n",
    "    # Path ke folder train dan test\n",
    "    train_real_path = os.path.join(base_dir, 'train', 'REAL')\n",
    "    train_fake_path = os.path.join(base_dir, 'train', 'FAKE')\n",
    "    test_real_path = os.path.join(base_dir, 'test', 'REAL')\n",
    "    test_fake_path = os.path.join(base_dir, 'test', 'FAKE')\n",
    "    \n",
    "    # List file-file gambar\n",
    "    train_real_files = [os.path.join(train_real_path, f) for f in os.listdir(train_real_path) if f.endswith('.jpg')]\n",
    "    train_fake_files = [os.path.join(train_fake_path, f) for f in os.listdir(train_fake_path) if f.endswith('.jpg')]\n",
    "    test_real_files = [os.path.join(test_real_path, f) for f in os.listdir(test_real_path) if f.endswith('.jpg')]\n",
    "    test_fake_files = [os.path.join(test_fake_path, f) for f in os.listdir(test_fake_path) if f.endswith('.jpg')]\n",
    "    \n",
    "    print(f\"Total data asli: {len(train_real_files)} train real, {len(train_fake_files)} train fake\")\n",
    "    print(f\"Total data test: {len(test_real_files)} test real, {len(test_fake_files)} test fake\")\n",
    "    \n",
    "    # Sampling random untuk masing-masing kelas\n",
    "    samples_per_class = sample_size // 4  # Bagi 4 untuk train/test dan real/fake\n",
    "    \n",
    "    train_real_sampled = random.sample(train_real_files, min(samples_per_class, len(train_real_files)))\n",
    "    train_fake_sampled = random.sample(train_fake_files, min(samples_per_class, len(train_fake_files)))\n",
    "    test_real_sampled = random.sample(test_real_files, min(samples_per_class, len(test_real_files)))\n",
    "    test_fake_sampled = random.sample(test_fake_files, min(samples_per_class, len(test_fake_files)))\n",
    "    \n",
    "    # Gabungkan file train dan label\n",
    "    train_files = train_real_sampled + train_fake_sampled\n",
    "    train_labels = [0] * len(train_real_sampled) + [1] * len(train_fake_sampled)  # 0=real, 1=fake\n",
    "    \n",
    "    # Gabungkan file test dan label\n",
    "    test_files = test_real_sampled + test_fake_sampled\n",
    "    test_labels = [0] * len(test_real_sampled) + [1] * len(test_fake_sampled)\n",
    "    \n",
    "    # Shuffle data\n",
    "    combined_train = list(zip(train_files, train_labels))\n",
    "    random.shuffle(combined_train)\n",
    "    train_files, train_labels = zip(*combined_train)\n",
    "    \n",
    "    combined_test = list(zip(test_files, test_labels))\n",
    "    random.shuffle(combined_test)\n",
    "    test_files, test_labels = zip(*combined_test)\n",
    "    \n",
    "    # Load dan preprocess gambar training\n",
    "    train_images = []\n",
    "    for file_path in train_files:\n",
    "        img = tf.keras.preprocessing.image.load_img(file_path, target_size=(64, 64))\n",
    "        img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        train_images.append(img_array)\n",
    "    \n",
    "    # Load dan preprocess gambar test\n",
    "    test_images = []\n",
    "    for file_path in test_files:\n",
    "        img = tf.keras.preprocessing.image.load_img(file_path, target_size=(64, 64))\n",
    "        img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        test_images.append(img_array)\n",
    "    \n",
    "    # Konversi ke numpy array\n",
    "    X_train = np.array(train_images)\n",
    "    y_train = np.array(train_labels)\n",
    "    X_test = np.array(test_images)\n",
    "    y_test = np.array(test_labels)\n",
    "    \n",
    "    # Normalisasi piksel ke [0,1]\n",
    "    X_train = X_train / 255.0\n",
    "    X_test = X_test / 255.0\n",
    "    \n",
    "    # Split data training untuk membuat validation set\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=val_split, random_state=random_state, stratify=y_train\n",
    "    )\n",
    "    \n",
    "    # One-hot encoding untuk label\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, 2)\n",
    "    y_val = tf.keras.utils.to_categorical(y_val, 2)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, 2)\n",
    "    \n",
    "    print(f\"Data yang digunakan: {len(X_train)} training, {len(X_val)} validation, {len(X_test)} testing samples\")\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "def create_cnn_model(config_num, input_shape=(64, 64, 3), optimizer_name='adam'):\n",
    "    \"\"\"\n",
    "    Membuat model CNN berdasarkan konfigurasi yang ditentukan\n",
    "    \n",
    "    Args:\n",
    "        config_num: nomor konfigurasi (1-4)\n",
    "        input_shape: dimensi input gambar\n",
    "        optimizer_name: nama optimizer ('sgd', 'adam', 'adagrad', 'adadelta')\n",
    "    \n",
    "    Returns:\n",
    "        model Keras yang sudah dikompilasi\n",
    "    \"\"\"\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # Input layer\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "    \n",
    "    # Konfigurasi 1: 1 Conv, 1 MaxPool\n",
    "    if config_num == 1:\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        \n",
    "    # Konfigurasi 2: 2 Conv, 1 MaxPool\n",
    "    elif config_num == 2:\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "        model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        \n",
    "    # Konfigurasi 3: 3 Conv, 2 MaxPool\n",
    "    elif config_num == 3:\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "        model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        \n",
    "    # Konfigurasi 4: 4 Conv, 2 MaxPool\n",
    "    elif config_num == 4:\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "        model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    # Flatten dan Fully Connected Layers\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(2, activation='softmax'))\n",
    "    \n",
    "    # Pilih optimizer berdasarkan nama\n",
    "    if optimizer_name.lower() == 'sgd':\n",
    "        opt = optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "    elif optimizer_name.lower() == 'adam':\n",
    "        opt = optimizers.Adam()\n",
    "    elif optimizer_name.lower() == 'adagrad':\n",
    "        opt = optimizers.Adagrad()\n",
    "    elif optimizer_name.lower() == 'adadelta':\n",
    "        opt = optimizers.Adadelta()\n",
    "    else:\n",
    "        raise ValueError(f\"Optimizer {optimizer_name} tidak tersedia\")\n",
    "    \n",
    "    # Kompilasi model\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def k_fold_cross_validation(X, y, config_num, optimizer_name, n_splits=5, epochs=20, batch_size=32):\n",
    "    \"\"\"\n",
    "    Melakukan k-fold cross-validation\n",
    "    \n",
    "    Args:\n",
    "        X: data gambar\n",
    "        y: label\n",
    "        config_num: nomor konfigurasi CNN (1-4)\n",
    "        optimizer_name: nama optimizer\n",
    "        n_splits: jumlah fold\n",
    "        epochs: jumlah epochs per training\n",
    "        batch_size: ukuran batch\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary dengan hasil metrics\n",
    "    \"\"\"\n",
    "    # Inisialisasi K-Fold\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Metrics untuk tiap fold\n",
    "    fold_metrics = {\n",
    "        'accuracy': [],\n",
    "        'precision': [],\n",
    "        'recall': [],\n",
    "        'f1_score': [],\n",
    "        'loss': []\n",
    "    }\n",
    "    \n",
    "    fold_num = 1\n",
    "    \n",
    "    # Iterasi untuk setiap fold\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        print(f\"\\nTraining fold {fold_num}/{n_splits}\")\n",
    "        \n",
    "        # Split data untuk fold ini\n",
    "        X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "        \n",
    "        # Convert indices to integers for y (in case they're not)\n",
    "        train_idx = [int(i) for i in train_idx]\n",
    "        val_idx = [int(i) for i in val_idx]\n",
    "        \n",
    "        y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
    "        \n",
    "        # Buat dan latih model\n",
    "        model = create_cnn_model(config_num, input_shape=X.shape[1:], optimizer_name=optimizer_name)\n",
    "        \n",
    "        # Early stopping untuk mencegah overfitting\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "        \n",
    "        # Train model\n",
    "        history = model.fit(\n",
    "            X_train_fold, y_train_fold,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_val_fold, y_val_fold),\n",
    "            callbacks=[early_stop],\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Evaluasi model\n",
    "        loss, accuracy = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
    "        \n",
    "        # Prediksi untuk metrics tambahan\n",
    "        y_pred = model.predict(X_val_fold, verbose=0)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "        y_val_classes = np.argmax(y_val_fold, axis=1)\n",
    "        \n",
    "        # Hitung metrics tambahan\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            y_val_classes, y_pred_classes, average='weighted')\n",
    "        \n",
    "        # Simpan metrics\n",
    "        fold_metrics['accuracy'].append(accuracy)\n",
    "        fold_metrics['precision'].append(precision)\n",
    "        fold_metrics['recall'].append(recall)\n",
    "        fold_metrics['f1_score'].append(f1)\n",
    "        fold_metrics['loss'].append(loss)\n",
    "        \n",
    "        fold_num += 1\n",
    "    \n",
    "    # Hitung rata-rata metrics dari semua fold\n",
    "    avg_metrics = {key: np.mean(values) for key, values in fold_metrics.items()}\n",
    "    std_metrics = {key: np.std(values) for key, values in fold_metrics.items()}\n",
    "    \n",
    "    print(\"\\nK-Fold Cross-Validation Results:\")\n",
    "    print(f\"Average Accuracy: {avg_metrics['accuracy']:.4f} ± {std_metrics['accuracy']:.4f}\")\n",
    "    print(f\"Average Precision: {avg_metrics['precision']:.4f} ± {std_metrics['precision']:.4f}\")\n",
    "    print(f\"Average Recall: {avg_metrics['recall']:.4f} ± {std_metrics['recall']:.4f}\")\n",
    "    print(f\"Average F1-Score: {avg_metrics['f1_score']:.4f} ± {std_metrics['f1_score']:.4f}\")\n",
    "    \n",
    "    return fold_metrics, avg_metrics, std_metrics\n",
    "\n",
    "def visualize_results(results_df, results=None):\n",
    "    \"\"\"\n",
    "    Visualisasi hasil eksperimen\n",
    "    \n",
    "    Args:\n",
    "        results_df: DataFrame dengan hasil eksperimen\n",
    "        results: Dictionary dengan data hasil lengkap (opsional)\n",
    "    \"\"\"\n",
    "    # Buat folder untuk hasil visualisasi\n",
    "    os.makedirs('results', exist_ok=True)\n",
    "    \n",
    "    # Ekstrak data untuk visualisasi\n",
    "    configs = results_df['Configuration'].unique()\n",
    "    optimizers = results_df['Optimizer'].unique()\n",
    "    \n",
    "    # Konversi accuracy string ke float\n",
    "    accuracies = []\n",
    "    for acc_str in results_df['Accuracy']:\n",
    "        if '±' in acc_str:\n",
    "            acc_value = float(acc_str.split('±')[0].strip())\n",
    "        else:\n",
    "            acc_value = float(acc_str)\n",
    "        accuracies.append(acc_value)\n",
    "    \n",
    "    results_df['Accuracy_Value'] = accuracies\n",
    "    \n",
    "    # Plot perbandingan akurasi untuk setiap konfigurasi dan optimizer\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Buat grouped bar chart\n",
    "    bar_width = 0.2\n",
    "    index = np.arange(len(configs))\n",
    "    \n",
    "    for i, optimizer in enumerate(optimizers):\n",
    "        opt_data = results_df[results_df['Optimizer'] == optimizer]\n",
    "        plt.bar(index + i*bar_width, opt_data['Accuracy_Value'], bar_width,\n",
    "                label=optimizer)\n",
    "    \n",
    "    plt.xlabel('CNN Configuration')\n",
    "    plt.ylabel('Validation Accuracy')\n",
    "    plt.title('Performance Comparison of CNN Configurations and Optimizers')\n",
    "    plt.xticks(index + bar_width * (len(optimizers)-1)/2, configs)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.savefig('results/accuracy_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    # Heatmap untuk visualisasi performa\n",
    "    pivot_df = results_df.pivot_table(\n",
    "        index='Configuration', \n",
    "        columns='Optimizer',\n",
    "        values='Accuracy_Value'\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(pivot_df, annot=True, cmap='viridis', fmt='.4f')\n",
    "    plt.title('Accuracy Heatmap: Configuration vs Optimizer')\n",
    "    plt.savefig('results/accuracy_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    # Plot F1-Score juga\n",
    "    f1_scores = []\n",
    "    for f1_str in results_df['F1-Score']:\n",
    "        if '±' in f1_str:\n",
    "            f1_value = float(f1_str.split('±')[0].strip())\n",
    "        else:\n",
    "            f1_value = float(f1_str)\n",
    "        f1_scores.append(f1_value)\n",
    "    \n",
    "    results_df['F1_Value'] = f1_scores\n",
    "    \n",
    "    # Heatmap untuk F1-score\n",
    "    pivot_f1 = results_df.pivot_table(\n",
    "        index='Configuration', \n",
    "        columns='Optimizer',\n",
    "        values='F1_Value'\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(pivot_f1, annot=True, cmap='plasma', fmt='.4f')\n",
    "    plt.title('F1-Score Heatmap: Configuration vs Optimizer')\n",
    "    plt.savefig('results/f1_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    plt.close('all')\n",
    "    print(\"Visualisasi disimpan di folder 'results/'\")\n",
    "\n",
    "def run_k_fold_experiments(dataset_dir, sample_size=5000):\n",
    "    \"\"\"\n",
    "    Menjalankan eksperimen dengan k-fold cross-validation\n",
    "    \n",
    "    Args:\n",
    "        dataset_dir: direktori dataset\n",
    "        sample_size: jumlah sampel yang digunakan\n",
    "    \"\"\"\n",
    "    # Load dataset\n",
    "    x_train, y_train, x_val, y_val, x_test, y_test = load_cifake_dataset(\n",
    "        dataset_dir, sample_size=sample_size)\n",
    "    \n",
    "    # Gabung data train dan validation untuk k-fold CV\n",
    "    X_combined = np.concatenate([x_train, x_val])\n",
    "    y_combined = np.concatenate([y_train, y_val])\n",
    "    \n",
    "    # Konfigurasi yang akan diuji\n",
    "    configs = [1, 2, 3, 4]\n",
    "    optimizers = ['SGD', 'Adam', 'Adagrad', 'Adadelta']\n",
    "    \n",
    "    # Hasil untuk semua eksperimen\n",
    "    results = {}\n",
    "    \n",
    "    # Buat DataFrame untuk menyimpan hasil\n",
    "    results_df = pd.DataFrame(columns=['Configuration', 'Optimizer', 'Accuracy', 'Precision', \n",
    "                                      'Recall', 'F1-Score'])\n",
    "    row_idx = 0\n",
    "    \n",
    "    # Iterasi untuk setiap konfigurasi dan optimizer\n",
    "    for config in configs:\n",
    "        results[f\"config_{config}\"] = {}\n",
    "        for optimizer in optimizers:\n",
    "            print(f\"\\n\\n======= Running Config {config} with {optimizer} Optimizer (K-Fold) =======\")\n",
    "            \n",
    "            # Lakukan k-fold cross-validation\n",
    "            fold_metrics, avg_metrics, std_metrics = k_fold_cross_validation(\n",
    "                X_combined, y_combined, config, optimizer, n_splits=5, epochs=20)\n",
    "            \n",
    "            # Simpan hasil\n",
    "            results[f\"config_{config}\"][optimizer] = {\n",
    "                'fold_metrics': fold_metrics,\n",
    "                'avg_metrics': avg_metrics,\n",
    "                'std_metrics': std_metrics\n",
    "            }\n",
    "            \n",
    "            # Tambahkan ke DataFrame\n",
    "            results_df.loc[row_idx] = [\n",
    "                f\"Config {config}\",\n",
    "                optimizer,\n",
    "                f\"{avg_metrics['accuracy']:.4f} ± {std_metrics['accuracy']:.4f}\",\n",
    "                f\"{avg_metrics['precision']:.4f} ± {std_metrics['precision']:.4f}\",\n",
    "                f\"{avg_metrics['recall']:.4f} ± {std_metrics['recall']:.4f}\",\n",
    "                f\"{avg_metrics['f1_score']:.4f} ± {std_metrics['f1_score']:.4f}\"\n",
    "            ]\n",
    "            row_idx += 1\n",
    "    \n",
    "    # Simpan hasil ke CSV\n",
    "    results_df.to_csv('results/k_fold_experiment_results.csv', index=False)\n",
    "    \n",
    "    # Visualisasi hasil\n",
    "    visualize_results(results_df, results)\n",
    "    \n",
    "    # Cari konfigurasi terbaik\n",
    "    best_row = results_df.iloc[results_df['Accuracy_Value'].idxmax()]\n",
    "    best_config = int(best_row['Configuration'].split()[1])\n",
    "    best_optimizer = best_row['Optimizer']\n",
    "    \n",
    "    print(f\"\\nKonfigurasi terbaik: Config {best_config} dengan {best_optimizer}\")\n",
    "    print(f\"Accuracy: {best_row['Accuracy']}\")\n",
    "    print(f\"F1-Score: {best_row['F1-Score']}\")\n",
    "    \n",
    "    # Train model final dengan konfigurasi terbaik\n",
    "    print(\"\\n\\n======= Training Final Model dengan Konfigurasi Terbaik =======\")\n",
    "    final_model = create_cnn_model(best_config, input_shape=x_train.shape[1:], optimizer_name=best_optimizer)\n",
    "    \n",
    "    # Callbacks\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    checkpoint = ModelCheckpoint('results/best_model.h5', save_best_only=True, monitor='val_accuracy')\n",
    "    \n",
    "    # Train model\n",
    "    history = final_model.fit(\n",
    "        x_train, y_train,\n",
    "        epochs=30,\n",
    "        batch_size=32,\n",
    "        validation_data=(x_val, y_val),\n",
    "        callbacks=[early_stop, checkpoint],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluasi pada data test\n",
    "    test_loss, test_acc = final_model.evaluate(x_test, y_test)\n",
    "    print(f\"\\nTest accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    # Prediksi untuk confusion matrix\n",
    "    y_pred = final_model.predict(x_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_test_classes = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    # Metrics\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_test_classes, y_pred_classes, average='weighted')\n",
    "    \n",
    "    print(f\"Test Precision: {precision:.4f}\")\n",
    "    print(f\"Test Recall: {recall:.4f}\")\n",
    "    print(f\"Test F1-Score: {f1:.4f}\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "    \n",
    "    # Visualisasi confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['Real', 'Fake'],\n",
    "                yticklabels=['Real', 'Fake'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig('results/confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    # Plot learning curves\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/learning_curves.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    return results, results_df, (best_config, best_optimizer)\n",
    "\n",
    "def main():\n",
    "    # Cetak waktu mulai\n",
    "    start_time = datetime.now()\n",
    "    print(f\"Eksperimen dimulai pada: {start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    # Path ke dataset CIFAKE\n",
    "    dataset_dir = \"dataset\"  # Sesuaikan dengan lokasi dataset Anda\n",
    "    \n",
    "    # Buat folder untuk menyimpan hasil\n",
    "    os.makedirs('results', exist_ok=True)\n",
    "    \n",
    "    # Jalankan eksperimen dengan k-fold cross-validation\n",
    "    # Gunakan sample_size yang lebih kecil untuk pengujian awal\n",
    "    # Dengan spesifikasi komputer Anda, 5000 sampel seharusnya tidak masalah\n",
    "    results, results_df, best_config = run_k_fold_experiments(dataset_dir, sample_size=5000)\n",
    "    \n",
    "    # Cetak waktu selesai dan durasi\n",
    "    end_time = datetime.now()\n",
    "    duration = end_time - start_time\n",
    "    print(f\"\\nEksperimen selesai pada: {end_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"Total durasi: {duration}\")\n",
    "    print(f\"Konfigurasi terbaik: Config {best_config[0]} dengan optimizer {best_config[1]}\")\n",
    "    print(\"\\nHasil eksperimen disimpan di folder 'results/'\")\n",
    "    \n",
    "    return results, results_df, best_config\n",
    "\n",
    "# Jalankan program jika script dijalankan langsung\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
